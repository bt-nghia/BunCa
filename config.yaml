Youshu:
  data_path: './datasets'
  batch_size_train: 2048 # the batch size for training
  batch_size_test: 2048 # the batch size for testing
  topk: [10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  
  # search hyperparameters
  # the following are the best settings
  aug_type: "ED" # options: ED, MD, OP
  ed_interval: 1 # by how many epochs to dropout edge, default is 1
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs

  # the following dropout rates are with respect to the "aug_type", i.e., if aug_type is ED, the following dropout rates are for ED.
  item_level_ratios: [0.2] # the dropout ratio for item-view graph
  bundle_level_ratios: [0.2] # the dropout ratio for bundle-view graph
  bundle_agg_ratios: [0.2] # the dropout ratio for bundle-item affiliation graph

  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-4] # the l2 regularization weight: lambda_2
  c_lambdas: [0.04] # the contrastive loss weight: lambda_1
  c_temps: [0.25] # the temperature in the contrastive loss: tau

  epochs: 100 # number of epochs to train
  test_interval: 1 # by how many epochs to run the validation and testing.
  UI_layers: [0.7, 0.3]
  seed: 2023
  UB_coefs: [1, 1]
  UI_coefs: [1, 1]
  BI_coefs: [1, 1]
  sep: "\t"
  file_type: ".txt"

NetEase:
  data_path: './datasets'
  batch_size_train: 2048
  batch_size_test: 2048
  topk: [10, 20, 40, 80]
  neg_num: 1

  # the following are the best settings
  aug_type: "ED"
  ed_interval: 1
  embedding_sizes: [64]
  num_layerss: [1]
  lrs: [1.0e-3]
  item_level_ratios: [0.1]
  bundle_level_ratios: [0.3]
  bundle_agg_ratios: [0.1]
  l2_regs: [1.0e-4]

  c_lambdas: [0.1]
  c_temps: [0.25]

  epochs: 50
  test_interval: 5
  sep: "\t"
  file_type: ".txt"



iFashion:
  data_path: './datasets'
  batch_size_train: 2048
  batch_size_test: 2048
  topk: [10, 20, 40, 80]
  neg_num: 1

  # the following are the best settings
  aug_type: "ED"
  ed_interval: 1
  embedding_sizes: [64]
  num_layerss: [1]
  lrs: [1.0e-3]
  item_level_ratios: [0.2]
  bundle_level_ratios: [0.2]
  bundle_agg_ratios: [0]
  l2_regs: [4.0e-5]

  c_lambdas: [0.25]
  c_temps: [0.2]

  epochs: 50
  test_interval: 5 
  sep: "\t"
  file_type: ".txt"

#-------------------------------- hoang amazon datasets --------------------------------
food1:
  data_path: './datasets'
  batch_size_train: 128 # the batch size for training
  batch_size_test: 128 # the batch size for testing
  topk: [5, 10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  
  # search hyperparameters
  # the following are the best settings
  aug_type: "ED" # options: ED, MD, OP
  ed_interval: 1 # by how many epochs to dropout edge, default is 1
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs

  # the following dropout rates are with respect to the "aug_type", i.e., if aug_type is ED, the following dropout rates are for ED.
  item_level_ratios: [0.2] # the dropout ratio for item-view graph
  bundle_level_ratios: [0.2] # the dropout ratio for bundle-view graph
  bundle_agg_ratios: [0.2] # the dropout ratio for bundle-item affiliation graph

  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-4] # the l2 regularization weight: lambda_2
  c_lambdas: [0.04] # the contrastive loss weight: lambda_1
  c_temps: [0.25] # the temperature in the contrastive loss: tau

  epochs: 50 # number of epochs to train
  test_interval: 1 # by how many epochs to run the validation and testing.
  UI_layers: [0.7, 0.3]
  seed: 2023
  UB_coefs: [1, 1]
  UI_coefs: [1, 1]
  BI_coefs: [1, 1]
  sep: "\t"
  file_type: ".txt"


electronic1:
  data_path: './datasets'
  batch_size_train: 128 # the batch size for training
  batch_size_test: 128 # the batch size for testing
  topk: [10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  
  # search hyperparameters
  # the following are the best settings
  aug_type: "ED" # options: ED, MD, OP
  ed_interval: 1 # by how many epochs to dropout edge, default is 1
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs

  # the following dropout rates are with respect to the "aug_type", i.e., if aug_type is ED, the following dropout rates are for ED.
  item_level_ratios: [0.2] # the dropout ratio for item-view graph
  bundle_level_ratios: [0.2] # the dropout ratio for bundle-view graph
  bundle_agg_ratios: [0.2] # the dropout ratio for bundle-item affiliation graph

  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-4] # the l2 regularization weight: lambda_2
  c_lambdas: [0.04] # the contrastive loss weight: lambda_1
  c_temps: [0.25] # the temperature in the contrastive loss: tau

  epochs: 50 # number of epochs to train
  test_interval: 1 # by how many epochs to run the validation and testing.
  UI_layers: [0.7, 0.3]
  seed: 2023
  UB_coefs: [1, 1]
  UI_coefs: [1, 1]
  BI_coefs: [1, 1]
  sep: "\t"
  file_type: ".txt"


clothing1:
  data_path: './datasets'
  batch_size_train: 128 # the batch size for training
  batch_size_test: 128 # the batch size for testing
  topk: [10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  
  # search hyperparameters
  # the following are the best settings
  aug_type: "ED" # options: ED, MD, OP
  ed_interval: 1 # by how many epochs to dropout edge, default is 1
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs

  # the following dropout rates are with respect to the "aug_type", i.e., if aug_type is ED, the following dropout rates are for ED.
  item_level_ratios: [0.2] # the dropout ratio for item-view graph
  bundle_level_ratios: [0.2] # the dropout ratio for bundle-view graph
  bundle_agg_ratios: [0.2] # the dropout ratio for bundle-item affiliation graph

  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-4] # the l2 regularization weight: lambda_2
  c_lambdas: [0.04] # the contrastive loss weight: lambda_1
  c_temps: [0.25] # the temperature in the contrastive loss: tau

  epochs: 50 # number of epochs to train
  test_interval: 1 # by how many epochs to run the validation and testing.
  UI_layers: [0.7, 0.3]
  seed: 2023
  UB_coefs: [1, 1]
  UI_coefs: [1, 1]
  BI_coefs: [1, 1]
  sep: "\t"
  file_type: ".txt"


# ------------------- hai amazon datasets ---------------------
food:
  data_path: './datasets'
  batch_size_train: 128 # the batch size for training
  batch_size_test: 128 # the batch size for testing
  topk: [5, 10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  
  # search hyperparameters
  # the following are the best settings
  aug_type: "ED" # options: ED, MD, OP
  ed_interval: 1 # by how many epochs to dropout edge, default is 1
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs

  # the following dropout rates are with respect to the "aug_type", i.e., if aug_type is ED, the following dropout rates are for ED.
  item_level_ratios: [0.2] # the dropout ratio for item-view graph
  bundle_level_ratios: [0.2] # the dropout ratio for bundle-view graph
  bundle_agg_ratios: [0.2] # the dropout ratio for bundle-item affiliation graph

  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-4] # the l2 regularization weight: lambda_2
  c_lambdas: [0.04] # the contrastive loss weight: lambda_1
  c_temps: [0.25] # the temperature in the contrastive loss: tau

  epochs: 50 # number of epochs to train
  test_interval: 1 # by how many epochs to run the validation and testing.
  UI_layers: [0.7, 0.3]
  seed: 2023
  UB_coefs: [1, 1]
  UI_coefs: [1, 1]
  BI_coefs: [1, 1]
  sep: "\t"
  file_type: ".txt"


electronic:
  data_path: './datasets'
  batch_size_train: 128 # the batch size for training
  batch_size_test: 128 # the batch size for testing
  topk: [10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  
  # search hyperparameters
  # the following are the best settings
  aug_type: "ED" # options: ED, MD, OP
  ed_interval: 1 # by how many epochs to dropout edge, default is 1
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs

  # the following dropout rates are with respect to the "aug_type", i.e., if aug_type is ED, the following dropout rates are for ED.
  item_level_ratios: [0.2] # the dropout ratio for item-view graph
  bundle_level_ratios: [0.2] # the dropout ratio for bundle-view graph
  bundle_agg_ratios: [0.2] # the dropout ratio for bundle-item affiliation graph

  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-4] # the l2 regularization weight: lambda_2
  c_lambdas: [0.04] # the contrastive loss weight: lambda_1
  c_temps: [0.25] # the temperature in the contrastive loss: tau

  epochs: 50 # number of epochs to train
  test_interval: 1 # by how many epochs to run the validation and testing.
  UI_layers: [0.7, 0.3]
  seed: 2023
  UB_coefs: [1, 1]
  UI_coefs: [1, 1]
  BI_coefs: [1, 1]
  sep: "\t"
  file_type: ".txt"


clothing:
  data_path: './datasets'
  batch_size_train: 128 # the batch size for training
  batch_size_test: 128 # the batch size for testing
  topk: [10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  
  # search hyperparameters
  # the following are the best settings
  aug_type: "ED" # options: ED, MD, OP
  ed_interval: 1 # by how many epochs to dropout edge, default is 1
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs

  # the following dropout rates are with respect to the "aug_type", i.e., if aug_type is ED, the following dropout rates are for ED.
  item_level_ratios: [0.2] # the dropout ratio for item-view graph
  bundle_level_ratios: [0.2] # the dropout ratio for bundle-view graph
  bundle_agg_ratios: [0.2] # the dropout ratio for bundle-item affiliation graph

  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-4] # the l2 regularization weight: lambda_2
  c_lambdas: [0.04] # the contrastive loss weight: lambda_1
  c_temps: [0.25] # the temperature in the contrastive loss: tau

  epochs: 50 # number of epochs to train
  test_interval: 1 # by how many epochs to run the validation and testing.
  UI_layers: [0.7, 0.3]
  seed: 2023
  UB_coefs: [1, 1]
  UI_coefs: [1, 1]
  BI_coefs: [1, 1]
  sep: "\t"
  file_type: ".txt"